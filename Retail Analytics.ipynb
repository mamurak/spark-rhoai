{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98881bba-0eee-43f3-b5d5-39fda688a488",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fsspec s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a49214-9664-43bd-af63-3b7239ec99d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "from os import getenv\n",
    "from warnings import filterwarnings\n",
    "\n",
    "filterwarnings('ignore')\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import (\n",
    "    avg, col, desc, lag, lead, to_date, sum, trim, upper, when\n",
    ")\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70d427f-19ee-4e93-97d7-9f8e43ee90e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_endpoint_url = getenv('AWS_S3_ENDPOINT')\n",
    "s3_access_key_id = getenv('AWS_ACCESS_KEY_ID')\n",
    "s3_secret_access_key = getenv('AWS_SECRET_ACCESS_KEY')\n",
    "s3_bucket_name = getenv('AWS_S3_BUCKET')\n",
    "print(f'S3 endpoint: {s3_endpoint_url}\\n'\n",
    "      f'S3 bucket: {s3_bucket_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d03dc53-a29f-4097-b7c2-1cc06eca9743",
   "metadata": {},
   "outputs": [],
   "source": [
    "SparkSession.stop\n",
    "\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName('Retail Analytics')\n",
    "    .config('spark.hadoop.fs.s3a.access.key', s3_access_key_id)\n",
    "    .config('spark.hadoop.fs.s3a.secret.key', s3_secret_access_key)\n",
    "    .config('spark.hadoop.fs.s3a.endpoint', s3_endpoint_url)\n",
    "    .config('spark.hadoop.fs.s3a.impl', 'org.apache.hadoop.fs.s3a.S3AFileSystem')\n",
    "    .config('spark.hadoop.fs.s3a.path.style.access', 'true')\n",
    "    .config('spark.hadoop.fs.s3a.connection.ssl.enabled', 'false')\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "\n",
    "def quiet_logs(sc):\n",
    "    logger = sc._jvm.org.apache.log4j\n",
    "    logger.LogManager.getLogger('org').setLevel(logger.Level.ERROR)\n",
    "    logger.LogManager.getLogger('akka').setLevel(logger.Level.ERROR)\n",
    "\n",
    "\n",
    "sc = SparkContext.getOrCreate();\n",
    "quiet_logs(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9846bf6-a3e1-4ce6-9a51-9a03aac52ccf",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3cb446-5e98-46e5-853e-e734898c6d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    # remove missing values\n",
    "    df = df.dropna()\n",
    "    # remove duplicate data\n",
    "    df = df.dropDuplicates()\n",
    "    return df\n",
    "\n",
    "\n",
    "def read_data(spark, file_format, file_path):\n",
    "    s3_path = f's3a://{s3_bucket_name}/{file_path}'\n",
    "    file_reader = spark.read.format(file_format)\n",
    "    if file_format == 'csv':\n",
    "        data = file_reader.load(s3_path, header=True)\n",
    "    else:\n",
    "        data = file_reader.load(s3_path)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f83750f-8bc0-44eb-985b-d0c2af7b8d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "sales_df = read_data(spark, 'csv', 'sales.csv')\n",
    "stock_df = read_data(spark, 'json', 'stock.json')\n",
    "supplier_df = read_data(spark, 'json', 'supplier.json')\n",
    "customer_df = read_data(spark, 'csv', 'customer.csv')\n",
    "market_df = read_data(spark, 'csv', 'market.csv')\n",
    "logistic_df = read_data(spark, 'csv', 'logistic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46e3a97-9087-4014-a128-d61c6d1b4425",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f0c911-5d5f-41b3-b288-06863a0a4b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fdb090-13ad-4b9c-96d5-c8fed1b4cbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "supplier_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5694c668-73d1-49e0-97df-6478ff666602",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf985a67-9ec9-45a1-8474-bd0ab76a8c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "market_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4824489-763a-422f-8871-bc2a94724208",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd957dbf-6610-482e-bde6-a49875b3fde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleaning\n",
    "sales_df = clean_data(sales_df)\n",
    "stock_df = clean_data(stock_df)\n",
    "supplier_df = clean_data(supplier_df)\n",
    "customer_df = clean_data(customer_df)\n",
    "market_df = clean_data(market_df)\n",
    "logistic_df = clean_data(logistic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914f3e75-ff44-481e-8c41-c4d992eedbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert date columns to date type\n",
    "sales_df = sales_df.withColumn('date_of_sale', to_date(col('date_of_sale')))\n",
    "stock_df = stock_df.withColumn('date_received', to_date(col('date_received')))\n",
    "supplier_df = supplier_df.withColumn('date_ordered', to_date(col('date_ordered')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b2c1f3-d5a0-4e51-9a47-b5caceb997cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize case of string columns\n",
    "sales_df = sales_df.withColumn('product_name', upper(col('product_name')))\n",
    "stock_df = stock_df.withColumn('product_name', upper(col('product_name')))\n",
    "stock_df = stock_df.withColumn('location', upper(col('location')))\n",
    "supplier_df = supplier_df.withColumn('product_name', upper(col('product_name')))\n",
    "customer_df = customer_df.withColumn('customer_name', upper(col('customer_name')))\n",
    "market_df = market_df.withColumn('product_name', upper(col('product_name')))\n",
    "logistic_df = logistic_df.withColumn('product_name', upper(col('product_name')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302fd9c0-2e25-43c0-bc9b-b3732432c8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove leading and trailing whitespaces\n",
    "sales_df = sales_df.withColumn('product_name', trim(col('product_name')))\n",
    "stock_df = stock_df.withColumn('location', trim(col('location')))\n",
    "supplier_df = supplier_df.withColumn('product_name', trim(col('product_name')))\n",
    "customer_df = customer_df.withColumn('customer_name', trim(col('customer_name')))\n",
    "market_df = market_df.withColumn('product_name', trim(col('product_name')))\n",
    "logistic_df = logistic_df.withColumn('product_name', trim(col('product_name')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225add10-c100-4faa-93e2-cd4cc5c5f413",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac891b1-01dd-4fb9-bb7f-a7a4eab3c52c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check for invalid values\n",
    "sales_df = sales_df.filter(col('product_name').isNotNull())\n",
    "stock_df = stock_df.filter(col('location').isNotNull())\n",
    "customer_df = customer_df.filter(col('gender').isin('male', 'female'))\n",
    "market_df = market_df.filter(col('product_name').isNotNull())\n",
    "logistic_df = logistic_df.filter(col('product_name').isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404755a7-2c17-4ac9-bfe5-4256a8cb5699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop extra columns\n",
    "market_df = market_df.drop('price')\n",
    "supplier_df = supplier_df.drop('price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fd23ca-5766-4793-82af-b4d8f7e7dc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join all data\n",
    "data_int = (\n",
    "    sales_df.join(stock_df, 'product_name', 'leftouter')\n",
    "            .join(supplier_df, 'product_name', 'leftouter')\n",
    "            .join(market_df, 'product_name', 'leftouter')\n",
    "            .join(logistic_df, 'product_name', 'leftouter')\n",
    "            .join(customer_df, 'customer_id', 'leftouter')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9f167e-b3d8-40f9-8dff-46954d770fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_int.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe0167b-4b07-4449-8869-789db4158b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_int.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be85126-e72c-4485-9e89-44b3cde387e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the cleaned data\n",
    "s3_path = f's3a://{s3_bucket_name}/cleaned.parquet'\n",
    "try:\n",
    "    data_int.write.format('parquet').save(s3_path)\n",
    "except Exception:\n",
    "    print('write failed')\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print('Time taken for Data Cleaning: ', end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb656c3-540c-4601-84c1-2a25c068db60",
   "metadata": {},
   "source": [
    "# Data analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4391e274-a135-4a15-a185-0b07f866243f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO VARIOUS RETAIL DATA ANALYTICS\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# read cleaned data\n",
    "\n",
    "data = read_data(spark, 'parquet', 'cleaned.parquet')\n",
    "\n",
    "# Case when statement to create a new column to indicate whether the product is perishable or not:\n",
    "\n",
    "data = data.withColumn(\n",
    "    'perishable', when(col('shelf_life') <= 30, 'yes').otherwise('no')\n",
    ")\n",
    "\n",
    "# You can use the when() and otherwise() functions to create new columns based on certain conditions:\n",
    "\n",
    "data = data.withColumn(\n",
    "    'sales_status', when(col('quantity_sold') > 50, 'good').otherwise('bad')\n",
    ")\n",
    "\n",
    "# create a window to perform time series analysis\n",
    "window = Window.partitionBy('product_name').orderBy('date_of_sale')\n",
    "\n",
    "# calculate the rolling average of sales for each product\n",
    "time_series_df = data.withColumn(\n",
    "    'rolling_avg_sales', avg('quantity_sold').over(window)\n",
    ")\n",
    "\n",
    "# use window function for forecasting\n",
    "\n",
    "forecast_df = (\n",
    "    time_series_df\n",
    "    .withColumn(\n",
    "        'prev_sales', lag('rolling_avg_sales').over(window))\n",
    "    .withColumn('next_sales', lead('rolling_avg_sales').over(window))\n",
    ")\n",
    "\n",
    "# Calculate the average price of a product, grouped by supplier\n",
    "forecast_df.groupBy('sup_id').agg({'price': 'avg'}).show()\n",
    "\n",
    "# Calculate the total quantity in stock and total sales by supplier\n",
    "(\n",
    "    forecast_df.groupBy('sup_id')\n",
    "               .agg({'quantity_in_stock': 'sum', 'price': 'sum'})\n",
    "               .show()\n",
    ")\n",
    "\n",
    "# Calculate the number of perishable v/s non-perishable product per location\n",
    "forecast_df.groupBy('perishable').agg({'perishable': 'count'}).show()\n",
    "\n",
    "# Calculate number of good v/s bad sales status per location\n",
    "forecast_df.groupBy('sales_status').agg({'sales_status': 'count'}).show()\n",
    "\n",
    "# Count the number of sales that contain a 10% off promotion\n",
    "countt = (\n",
    "    forecast_df.filter(forecast_df['contains_promotion'].contains('10% off'))\n",
    "               .count()\n",
    ")\n",
    "print(countt)\n",
    "# Perform some complex analysis on the DataFrame\n",
    "\n",
    "# Calculate the total sales, quantity sold by product and location\n",
    "total_sales_by_product_location = (\n",
    "    forecast_df.groupBy('product_name', 'location')\n",
    "               .agg(\n",
    "                   sum('price').alias('total_price'),\n",
    "                   sum('quantity_ordered').alias('total_quantity_sold'),\n",
    "                   avg('quantity_sold').alias('avg_quantity_sold'))\n",
    "               .sort(desc('total_price'))\n",
    ")\n",
    "\n",
    "# Group the data by product_name\n",
    "grouped_df = forecast_df.groupBy('product_name')\n",
    "\n",
    "# Sum the quantity_in_stock, quantity_ordered, quantity_sold, and (price * quantity_sold) for each group\n",
    "aggregated_df = (\n",
    "    grouped_df.agg(\n",
    "        sum('quantity_in_stock').alias('total_quantity_in_stock'),\n",
    "        avg('price').alias('average_price'),\n",
    "        sum('quantity_ordered').alias('total_quantity_ordered'),\n",
    "        sum('quantity_sold').alias('total_quantity_sold'),\n",
    "        sum(col('price') * col('quantity_sold')).alias('total_sales'),\n",
    "        sum('prev_sales').alias('total_prev_sales'),\n",
    "        sum('next_sales').alias('total_next_sales'),\n",
    "    ).sort(desc('total_sales'))\n",
    ")\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print('Time taken for Data Analysis: ', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e82083-8c5e-4337-9937-087540d966c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec15d4ec-64ea-4008-a48b-fe11ec2cde66",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sales_by_product_location.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bfdcd8-66b6-4126-bfc4-4d30a7d50662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE THE AGGREGATES TO DISK\n",
    "timestamp = datetime.now().strftime('%y%m%d%H%M')\n",
    "\n",
    "aggregated_s3_path = f's3a://{s3_bucket_name}/aggregated-{timestamp}.parquet'\n",
    "aggregated_df.write.format('parquet').save(aggregated_s3_path)\n",
    "\n",
    "total_sales_s3_path = f's3a://{s3_bucket_name}/total_sales-{timestamp}.parquet'\n",
    "total_sales_by_product_location.write.format('parquet').save(total_sales_s3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e814c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b8578e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.14",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
